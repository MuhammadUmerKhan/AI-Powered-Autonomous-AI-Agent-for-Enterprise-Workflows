# üìë Documentation `utils.py`: Document Classifier and Chat Application

## üåü Overview

This repository contains a Python application built with Streamlit that integrates language models (LLMs) and embedding models to create a chat-based interface for document classification, question answering, and text processing. The application uses the `langchain_groq` library to interact with the Grok API, `SentenceTransformer` for embeddings, and Streamlit for a user-friendly web interface. It includes logging, prompt loading, and session management to ensure robust functionality and user interaction. üöÄ

## üìÇ Files Included

This repository includes the following key components:

- **main script (e.g., `app.py`)**: The Python script provided, which sets up the application, configures LLMs, embeddings, and chat functionality.
- **`config.py`**: A configuration file (imported as `CONFIG`) containing API keys, file paths, and constants (e.g., `GROK_API_KEY`, prompt paths).
- **prompts directory**: Contains text files for prompts used in LLM interactions (e.g., `clause_extraction.txt`, `risk_analysis.txt`, etc.).
- **data directory**: Contains sample data files, such as PDFs or text documents for processing.
- **logs directory**: Automatically created to store log files (e.g., `document_classifier.log`).

## üéØ Purpose

The purpose of this application is to:

- Provide a chat interface for users to interact with AI models for tasks like document classification, question answering, and summarization.
- Load and configure LLMs (via Grok API) and embedding models (via SentenceTransformer) for processing natural language.
- Manage chat history, log interactions, and handle errors gracefully using logging and session state synchronization.
- Enable developers to extend functionality for specific use cases, such as legal document analysis or customer support.

## üöÄ Getting Started

Follow these steps to set up and run the application:

1. **Clone the Repository**:
   Use the following command to clone this repository to your local machine:
   ```bash
   git clone <repository-url>
   ```
   (Replace `<repository-url>` with the actual URL if applicable.)

2. **Install Dependencies**:
   Navigate to the project directory and install required packages:
   ```bash
   cd <project-directory>
   pip install langchain-groq streamlit sentence-transformers python-dotenv
   ```

3. **Set Up Environment Variables**:
   Ensure your `config.py` or `.env` file contains the `GROK_API_KEY`. For example, in `config.py`:
   ```python
   GROQ_API_KEY = "your_api_key_here"
   ```
   Replace `"your_api_key_here"` with your actual Grok API key.

4. **Verify File Structure**:
   Ensure the following directories and files exist:
   - `prompts/clause_extraction.txt`, `prompts/risk_analysis.txt`, etc.
   - `data/Example-One-Way-Non-Disclosure-Agreement.pdf` (or similar).
   - `config.py` with necessary configurations.

5. **Run the Application**:
   Launch the Streamlit app using:
   ```bash
   streamlit run app.py
   ```
   (Replace `app.py` with the actual script name if different.) Open your web browser to the provided Streamlit URL (usually `http://localhost:8501`).

## üìù Usage

The application provides a chat interface where users can:

- Interact with the LLM by asking questions or providing documents for analysis.
- View chat history, which persists across sessions using Streamlit‚Äôs session state.
- Receive responses generated by the configured LLM (`ChatGroq`) and embeddings (`SentenceTransformer`).

Key features include:

- **LLM Configuration**: Use `configure_llm()` to set up the Grok model with a specified `MODEL_NAME`.
- **Embedding Model**: Load and cache the `SentenceTransformer` model (`all-MiniLM-L6-v2`) for text embeddings.
- **Chat History**: Managed via the `enable_chat_history` decorator and `display_msg` function, ensuring messages are stored and displayed in the UI.
- **Logging**: All interactions and errors are logged to `logs/document_classifier.log` and the console.

To use, simply type a question or command in the Streamlit chat interface, and the application will respond with the LLM‚Äôs output.

## ü§ù Contributing

Contributions to enhance this application are welcome! Please follow these steps:

1. Fork the repository.
2. Create a new branch for your feature or bug fix.
3. Submit a pull request with your changes.

For major changes, please open an issue to discuss your ideas first. üí°